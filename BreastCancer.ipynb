{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BreastCancer.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "Oex88qd38Thn",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "In this first cell we upload the CSV files that contain the pre-sorted and pre-normalized data. \n",
        "This uses the Wisconsin breast cancer dataset, sorted into training and test sets with the 'input' values to the Neural Network as 'X' values, and the expected 'output' (0 for benign and 1 for malignant) as the 'Y' values.\n"
      ]
    },
    {
      "metadata": {
        "id": "m_NRnXsJzphf",
        "colab_type": "code",
        "outputId": "539380ef-ec7c-4f8e-ff4f-7979bd05b843",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 179
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "file = files.upload()\n",
        "X_train = pd.read_csv(\"xtrain.csv\", header=None)\n",
        "Y_train = pd.read_csv(\"ytrain.csv\", header=None)\n",
        "X_test = pd.read_csv(\"xtest.csv\", header=None)\n",
        "Y_test = pd.read_csv(\"ytest.csv\", header=None)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-bfdd53ca-b1b0-43d9-bb1b-9cdf2dafffdf\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-bfdd53ca-b1b0-43d9-bb1b-9cdf2dafffdf\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving xtest.csv to xtest.csv\n",
            "Saving xtrain.csv to xtrain.csv\n",
            "Saving ytest.csv to ytest.csv\n",
            "Saving ytrain.csv to ytrain.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "bL4z0BArzqff",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Now we use Keras to define a Neural Network that will be trained off of our data. This Neural Network will then be used to predict if new samples are malignant or benign. "
      ]
    },
    {
      "metadata": {
        "id": "LoWtmalR80De",
        "colab_type": "code",
        "outputId": "d0764321-f95e-4fc7-edf6-0001ebf2ef36",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        }
      },
      "cell_type": "code",
      "source": [
        "#Required Imports\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "\n",
        "#Initialising the ANN\n",
        "classifier = Sequential() \n",
        "#Input layer\n",
        "classifier.add(Dense(units = 16, activation = 'relu', input_dim = 30))\n",
        "#Dense layers are fully connected layers\n",
        "#2 dense layers each with 8 nodes and relu activation functions\n",
        "classifier.add(Dense(units = 8, activation = 'relu'))\n",
        "classifier.add(Dense(units = 8, activation = 'relu'))\n",
        "#Output layer\n",
        "classifier.add(Dense(units = 1, activation = 'sigmoid'))\n",
        "\n",
        "#What does the model look like\n",
        "from keras.utils import plot_model\n",
        "plot_model(classifier, to_file='model.png',show_shapes=True)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "cJ_MStxe9CbN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Once the Neural Network is defined, we have to specify is the optimizer and loss function"
      ]
    },
    {
      "metadata": {
        "id": "wR2O00E39C7E",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "classifier.compile(optimizer = 'rmsprop', loss = 'binary_crossentropy')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Mn9WPqaP9RmN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We now train the neural network using Classifier.fit, passing it the training data (X and Y values). The ANN will then spot the patterns in the data, and build a neural network that can use them to make predictions."
      ]
    },
    {
      "metadata": {
        "id": "1QlYnFgH9N49",
        "colab_type": "code",
        "outputId": "4b8cc836-a288-4a74-9288-106529a6e5dc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1840
        }
      },
      "cell_type": "code",
      "source": [
        "classifier.fit(X_train, Y_train, batch_size = 1, epochs = 50)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Epoch 1/50\n",
            "455/455 [==============================] - 1s 2ms/step - loss: 0.4173\n",
            "Epoch 2/50\n",
            "455/455 [==============================] - 0s 1ms/step - loss: 0.1216\n",
            "Epoch 3/50\n",
            "455/455 [==============================] - 0s 965us/step - loss: 0.1027\n",
            "Epoch 4/50\n",
            "455/455 [==============================] - 0s 958us/step - loss: 0.0993\n",
            "Epoch 5/50\n",
            "455/455 [==============================] - 0s 960us/step - loss: 0.0893\n",
            "Epoch 6/50\n",
            "455/455 [==============================] - 0s 841us/step - loss: 0.0918\n",
            "Epoch 7/50\n",
            "455/455 [==============================] - 0s 796us/step - loss: 0.0867\n",
            "Epoch 8/50\n",
            "455/455 [==============================] - 0s 801us/step - loss: 0.0864\n",
            "Epoch 9/50\n",
            "455/455 [==============================] - 0s 770us/step - loss: 0.0891\n",
            "Epoch 10/50\n",
            "455/455 [==============================] - 0s 773us/step - loss: 0.0819\n",
            "Epoch 11/50\n",
            "455/455 [==============================] - 0s 832us/step - loss: 0.0791\n",
            "Epoch 12/50\n",
            "455/455 [==============================] - 0s 821us/step - loss: 0.0809\n",
            "Epoch 13/50\n",
            "455/455 [==============================] - 0s 814us/step - loss: 0.0758\n",
            "Epoch 14/50\n",
            "455/455 [==============================] - 0s 817us/step - loss: 0.0801\n",
            "Epoch 15/50\n",
            "455/455 [==============================] - 0s 863us/step - loss: 0.0788\n",
            "Epoch 16/50\n",
            "455/455 [==============================] - 0s 808us/step - loss: 0.0741\n",
            "Epoch 17/50\n",
            "455/455 [==============================] - 0s 798us/step - loss: 0.0961\n",
            "Epoch 18/50\n",
            "455/455 [==============================] - 0s 817us/step - loss: 0.0852\n",
            "Epoch 19/50\n",
            "455/455 [==============================] - 0s 837us/step - loss: 0.0803\n",
            "Epoch 20/50\n",
            "455/455 [==============================] - 0s 850us/step - loss: 0.0810\n",
            "Epoch 21/50\n",
            "455/455 [==============================] - 0s 839us/step - loss: 0.0736\n",
            "Epoch 22/50\n",
            "455/455 [==============================] - 0s 803us/step - loss: 0.0799\n",
            "Epoch 23/50\n",
            "455/455 [==============================] - 0s 809us/step - loss: 0.0763\n",
            "Epoch 24/50\n",
            "455/455 [==============================] - 0s 802us/step - loss: 0.0704\n",
            "Epoch 25/50\n",
            "455/455 [==============================] - 0s 807us/step - loss: 0.0690\n",
            "Epoch 26/50\n",
            "455/455 [==============================] - 0s 845us/step - loss: 0.0829\n",
            "Epoch 27/50\n",
            "455/455 [==============================] - 0s 830us/step - loss: 0.0758\n",
            "Epoch 28/50\n",
            "455/455 [==============================] - 0s 823us/step - loss: 0.0720\n",
            "Epoch 29/50\n",
            "455/455 [==============================] - 0s 872us/step - loss: 0.0651\n",
            "Epoch 30/50\n",
            "455/455 [==============================] - 0s 976us/step - loss: 0.0695\n",
            "Epoch 31/50\n",
            "455/455 [==============================] - 0s 929us/step - loss: 0.0705\n",
            "Epoch 32/50\n",
            "455/455 [==============================] - 0s 912us/step - loss: 0.0638\n",
            "Epoch 33/50\n",
            "455/455 [==============================] - 0s 874us/step - loss: 0.0611\n",
            "Epoch 34/50\n",
            "455/455 [==============================] - 0s 820us/step - loss: 0.0659\n",
            "Epoch 35/50\n",
            "455/455 [==============================] - 0s 824us/step - loss: 0.0558\n",
            "Epoch 36/50\n",
            "455/455 [==============================] - 0s 839us/step - loss: 0.0585\n",
            "Epoch 37/50\n",
            "455/455 [==============================] - 0s 844us/step - loss: 0.0737\n",
            "Epoch 38/50\n",
            "455/455 [==============================] - 0s 828us/step - loss: 0.0621\n",
            "Epoch 39/50\n",
            "455/455 [==============================] - 0s 832us/step - loss: 0.0614\n",
            "Epoch 40/50\n",
            "455/455 [==============================] - 0s 866us/step - loss: 0.0621\n",
            "Epoch 41/50\n",
            "455/455 [==============================] - 0s 864us/step - loss: 0.0610\n",
            "Epoch 42/50\n",
            "455/455 [==============================] - 0s 862us/step - loss: 0.0588\n",
            "Epoch 43/50\n",
            "455/455 [==============================] - 0s 855us/step - loss: 0.0510\n",
            "Epoch 44/50\n",
            "455/455 [==============================] - 0s 866us/step - loss: 0.0497\n",
            "Epoch 45/50\n",
            "455/455 [==============================] - 0s 912us/step - loss: 0.0521\n",
            "Epoch 46/50\n",
            "455/455 [==============================] - 0s 938us/step - loss: 0.0557\n",
            "Epoch 47/50\n",
            "455/455 [==============================] - 0s 909us/step - loss: 0.0556\n",
            "Epoch 48/50\n",
            "455/455 [==============================] - 0s 879us/step - loss: 0.0543\n",
            "Epoch 49/50\n",
            "455/455 [==============================] - 0s 934us/step - loss: 0.0484\n",
            "Epoch 50/50\n",
            "455/455 [==============================] - 0s 917us/step - loss: 0.0576\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f0d569dc9b0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "metadata": {
        "id": "yrnGgtfn9gsE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "To predict new values, the Neural Network uses classifier.predict. Let's it the test values for X (which have never been previously seen by the Neural Network) and it will give us back a set of predictions. These predicitons will be probabilities from 0-1, so lets make them whole numbers by saying that if they're are greater than .5, make them 1, else make them 0."
      ]
    },
    {
      "metadata": {
        "id": "xEaG0Tkx9fUU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "Y_pred = classifier.predict(X_test)\n",
        "Y_pred = [ 1 if y>=0.5 else 0 for y in Y_pred ]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oQK3Qo9h97OW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Now we can loop through the set of predicitons and actual values to compare them. If they are the same, increment 'correct', else incrememnt 'wrong'. "
      ]
    },
    {
      "metadata": {
        "id": "he_2VHJ_9yC1",
        "colab_type": "code",
        "outputId": "2a0c223d-7327-404e-d530-f347a3e4ab17",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2045
        }
      },
      "cell_type": "code",
      "source": [
        "#Print the actual value, prediction, and if they match or not\n",
        "def printResults(x,y,z):\n",
        "  if (x==1):\n",
        "    x=\"Malignant\"\n",
        "  else:\n",
        "    x=\"Benign\"\n",
        "  if (y==1):\n",
        "    y=\"Malignant\"\n",
        "  else:\n",
        "    y=\"Benign\"\n",
        "  print(z, \"actual->\",x,\"prediction ->\",y)\n",
        "\n",
        "#Counter variables\n",
        "total = 0\n",
        "correct = 0\n",
        "wrong = 0\n",
        "\n",
        "#Cycle through the predictions\n",
        "for i in range(len(Y_pred)):\n",
        "  total=total+1\n",
        "  if(Y_test.at[i,0] == Y_pred[i]): #if the prediction is correct\n",
        "    correct=correct+1\n",
        "    printResults(Y_test.at[i,0], Y_pred[i],\"CORRECT\")\n",
        "  else: #if the prediction is wrong\n",
        "    wrong=wrong+1\n",
        "    printResults(Y_test.at[i,0], Y_pred[i],\"WRONG\")\n",
        "\n",
        "#print final results\n",
        "print(\"Total \" + str(total))\n",
        "print(\"Correct \" + str(correct))\n",
        "print(\"Wrong \" + str(wrong))\n",
        "\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CORRECT actual-> Malignant prediction -> Malignant\n",
            "CORRECT actual-> Benign prediction -> Benign\n",
            "CORRECT actual-> Benign prediction -> Benign\n",
            "CORRECT actual-> Benign prediction -> Benign\n",
            "CORRECT actual-> Benign prediction -> Benign\n",
            "CORRECT actual-> Benign prediction -> Benign\n",
            "CORRECT actual-> Benign prediction -> Benign\n",
            "CORRECT actual-> Benign prediction -> Benign\n",
            "CORRECT actual-> Benign prediction -> Benign\n",
            "CORRECT actual-> Benign prediction -> Benign\n",
            "CORRECT actual-> Benign prediction -> Benign\n",
            "CORRECT actual-> Benign prediction -> Benign\n",
            "CORRECT actual-> Benign prediction -> Benign\n",
            "CORRECT actual-> Benign prediction -> Benign\n",
            "CORRECT actual-> Benign prediction -> Benign\n",
            "CORRECT actual-> Malignant prediction -> Malignant\n",
            "CORRECT actual-> Benign prediction -> Benign\n",
            "CORRECT actual-> Malignant prediction -> Malignant\n",
            "CORRECT actual-> Malignant prediction -> Malignant\n",
            "CORRECT actual-> Malignant prediction -> Malignant\n",
            "CORRECT actual-> Malignant prediction -> Malignant\n",
            "CORRECT actual-> Malignant prediction -> Malignant\n",
            "CORRECT actual-> Benign prediction -> Benign\n",
            "CORRECT actual-> Benign prediction -> Benign\n",
            "CORRECT actual-> Malignant prediction -> Malignant\n",
            "CORRECT actual-> Benign prediction -> Benign\n",
            "CORRECT actual-> Benign prediction -> Benign\n",
            "CORRECT actual-> Malignant prediction -> Malignant\n",
            "CORRECT actual-> Benign prediction -> Benign\n",
            "CORRECT actual-> Malignant prediction -> Malignant\n",
            "CORRECT actual-> Benign prediction -> Benign\n",
            "CORRECT actual-> Malignant prediction -> Malignant\n",
            "CORRECT actual-> Benign prediction -> Benign\n",
            "CORRECT actual-> Malignant prediction -> Malignant\n",
            "CORRECT actual-> Benign prediction -> Benign\n",
            "CORRECT actual-> Malignant prediction -> Malignant\n",
            "CORRECT actual-> Benign prediction -> Benign\n",
            "CORRECT actual-> Malignant prediction -> Malignant\n",
            "CORRECT actual-> Benign prediction -> Benign\n",
            "CORRECT actual-> Malignant prediction -> Malignant\n",
            "CORRECT actual-> Malignant prediction -> Malignant\n",
            "CORRECT actual-> Benign prediction -> Benign\n",
            "CORRECT actual-> Malignant prediction -> Malignant\n",
            "CORRECT actual-> Benign prediction -> Benign\n",
            "CORRECT actual-> Benign prediction -> Benign\n",
            "CORRECT actual-> Malignant prediction -> Malignant\n",
            "CORRECT actual-> Benign prediction -> Benign\n",
            "CORRECT actual-> Benign prediction -> Benign\n",
            "CORRECT actual-> Benign prediction -> Benign\n",
            "CORRECT actual-> Malignant prediction -> Malignant\n",
            "CORRECT actual-> Malignant prediction -> Malignant\n",
            "CORRECT actual-> Malignant prediction -> Malignant\n",
            "CORRECT actual-> Malignant prediction -> Malignant\n",
            "CORRECT actual-> Benign prediction -> Benign\n",
            "CORRECT actual-> Benign prediction -> Benign\n",
            "CORRECT actual-> Benign prediction -> Benign\n",
            "CORRECT actual-> Benign prediction -> Benign\n",
            "CORRECT actual-> Benign prediction -> Benign\n",
            "CORRECT actual-> Benign prediction -> Benign\n",
            "CORRECT actual-> Malignant prediction -> Malignant\n",
            "CORRECT actual-> Malignant prediction -> Malignant\n",
            "CORRECT actual-> Malignant prediction -> Malignant\n",
            "CORRECT actual-> Benign prediction -> Benign\n",
            "CORRECT actual-> Benign prediction -> Benign\n",
            "CORRECT actual-> Malignant prediction -> Malignant\n",
            "CORRECT actual-> Benign prediction -> Benign\n",
            "CORRECT actual-> Malignant prediction -> Malignant\n",
            "CORRECT actual-> Malignant prediction -> Malignant\n",
            "CORRECT actual-> Malignant prediction -> Malignant\n",
            "CORRECT actual-> Benign prediction -> Benign\n",
            "CORRECT actual-> Benign prediction -> Benign\n",
            "CORRECT actual-> Malignant prediction -> Malignant\n",
            "CORRECT actual-> Benign prediction -> Benign\n",
            "CORRECT actual-> Malignant prediction -> Malignant\n",
            "CORRECT actual-> Malignant prediction -> Malignant\n",
            "CORRECT actual-> Benign prediction -> Benign\n",
            "CORRECT actual-> Benign prediction -> Benign\n",
            "CORRECT actual-> Benign prediction -> Benign\n",
            "CORRECT actual-> Benign prediction -> Benign\n",
            "CORRECT actual-> Benign prediction -> Benign\n",
            "CORRECT actual-> Malignant prediction -> Malignant\n",
            "CORRECT actual-> Malignant prediction -> Malignant\n",
            "CORRECT actual-> Malignant prediction -> Malignant\n",
            "CORRECT actual-> Benign prediction -> Benign\n",
            "CORRECT actual-> Malignant prediction -> Malignant\n",
            "CORRECT actual-> Benign prediction -> Benign\n",
            "CORRECT actual-> Benign prediction -> Benign\n",
            "CORRECT actual-> Benign prediction -> Benign\n",
            "CORRECT actual-> Malignant prediction -> Malignant\n",
            "CORRECT actual-> Malignant prediction -> Malignant\n",
            "CORRECT actual-> Benign prediction -> Benign\n",
            "CORRECT actual-> Malignant prediction -> Malignant\n",
            "WRONG actual-> Benign prediction -> Malignant\n",
            "CORRECT actual-> Malignant prediction -> Malignant\n",
            "CORRECT actual-> Benign prediction -> Benign\n",
            "CORRECT actual-> Benign prediction -> Benign\n",
            "CORRECT actual-> Malignant prediction -> Malignant\n",
            "CORRECT actual-> Benign prediction -> Benign\n",
            "CORRECT actual-> Benign prediction -> Benign\n",
            "CORRECT actual-> Benign prediction -> Benign\n",
            "CORRECT actual-> Benign prediction -> Benign\n",
            "CORRECT actual-> Benign prediction -> Benign\n",
            "CORRECT actual-> Benign prediction -> Benign\n",
            "CORRECT actual-> Benign prediction -> Benign\n",
            "CORRECT actual-> Malignant prediction -> Malignant\n",
            "CORRECT actual-> Benign prediction -> Benign\n",
            "CORRECT actual-> Malignant prediction -> Malignant\n",
            "CORRECT actual-> Benign prediction -> Benign\n",
            "WRONG actual-> Malignant prediction -> Benign\n",
            "CORRECT actual-> Malignant prediction -> Malignant\n",
            "CORRECT actual-> Benign prediction -> Benign\n",
            "CORRECT actual-> Malignant prediction -> Malignant\n",
            "CORRECT actual-> Malignant prediction -> Malignant\n",
            "CORRECT actual-> Benign prediction -> Benign\n",
            "Total 114\n",
            "Correct 112\n",
            "Wrong 2\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}